<!DOCTYPE html>
<html lang="de">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>ParlaTONE – Forschungsblog zu §218</title>
  <link rel="stylesheet" href="styles.css" />
</head>
<body>
  <header class="site-header">
    <div class="container">
      <h1>ParlaTONE</h1>
      <p class="subtitle">Sprachwandel im Deutschen Bundestag zum §218 StGB</p>
    </div>
  </header>
  <main class="container">
    <section id="hinweis-llm">
      <h2>Hinweis: Zusammenarbeit mit einem LLM</h2>
      <p>
        Dieser Forschungsblog wurde in Zusammenarbeit mit einem
        <span class="glossary-term"
              data-definition="Ein Large Language Model (LLM) ist ein großes KI-Sprachmodell, das auf umfangreichen Textkorpora trainiert wurde und Texte verstehen und generieren kann.">
          Large Language Model (LLM)
        </span>
        erstellt. Alle Inhalte werden von mir als Projektverantwortliche*r überprüft,
        überarbeitet und – wo nötig – korrigiert oder ergänzt
        (<em>Expert in the Loop</em>). Unsichere Punkte werden im Projektverlauf explizit
        als offene Frage formuliert und später gemeinsam im Kurs diskutiert.
      </p>
    </section>
    <section id="projektuebersicht">
      <h2>Projektübersicht</h2>
      <p>
        <strong>Projektname:</strong> ParlaTONE – Sprachwandel im Deutschen Bundestag zu §218 StGB.
      </p>
      <p>
        <strong>Übergeordnete Idee:</strong> In ParlaTONE untersuche ich den politischen Diskurs rund um
        den Abtreibungsparagraphen §218 StGB im Deutschen Bundestag. Im Zentrum steht die Frage,
        wie sich der <strong>Ton</strong> der Debatten über mehrere Jahre verändert und wie sich
        unterschiedliche Parteien und Geschlechter der Redner*innen sprachlich positionieren.
      </p>
      <p>
        <strong>Forschungsfrage (Arbeitsfassung):</strong><br />
        Wie hat sich der Ton im Parlamentsdiskurs zu §218 im Laufe der letzten Jahre verändert, und
        welche Unterschiede zeigen sich zwischen Parteien und Geschlechtern der Redner*innen?
      </p>
      <p>
        <strong>Kontext:</strong> §218 ist seit Jahrzehnten gesellschaftlich umkämpft. Debatten um
        reproduktive Rechte, medizinische Versorgung und religiöse bzw. moralische Positionen prägen
        den Diskurs. Die Plenarprotokolle des Bundestags bieten eine reich strukturierte, offizielle
        Quelle, um diese Auseinandersetzungen in ihrer sprachlichen Form zu analysieren.
      </p>
    </section>
    <section id="daten">
      <h2>Datenbasis</h2>
      <p>
        <strong>Quelle:</strong> Plenarprotokolle des Deutschen Bundestages, die über das
        Open-Data-Angebot des Bundestags bzw. verwandte Korpora als XML/TEI und weitere Formate
        zur Verfügung stehen.
      </p>
      <p>
        <strong>Geplanter Korpus:</strong> Sitzungen, in denen §218 (und eng verwandte Themen wie
        Schwangerschaftsabbruch, reproduktive Selbstbestimmung, §219a) explizit diskutiert werden.
        Der genaue Zeitraum wird im Projektverlauf präzise definiert und dokumentiert (Arbeitsannahme:
        Debatten aus den 2010er und frühen 2020er Jahren).
      </p>
      <p>
        <strong>Struktur:</strong> Die Protokolle liegen in einem XML/TEI-Format vor, das
        Redebeiträge, Zwischenrufe, formale Elemente (z.&nbsp;B. Sitzungsleitung) und Metadaten
        (u.&nbsp;a. Datum, Fraktion, Name der Redner*innen) unterscheidet. Für ParlaTONE werden diese
        Daten zunächst in eine tabellarische Struktur überführt (z.&nbsp;B. eine Zeile pro Redebeitrag).
      </p>
      <p>
        <strong>Beispielhafter Datensatz (Zielzustand):</strong>
      </p>
      <ul>
        <li>Spalten: <code>speech_id</code>, <code>speaker_name</code>, <code>party</code>, <code>gender</code>,
            <code>date</code>, <code>session_id</code>, <code>text</code></li>
        <li>Filter: Nur Redebeiträge, in denen §218 bzw. eng verwandte Begriffe vorkommen</li>
        <li>Metadaten-Erweiterung: Parteien und – wo möglich – Geschlechtszuordnung der Redner*innen</li>
      </ul>
      <p>
        <em>Offene Frage:</em> Welche zusätzlichen Metadaten (z.&nbsp;B. Berufsgruppen, Ausschusszugehörigkeit)
        sind für die Analyse wirklich relevant und realistisch zu erheben?
      </p>
    </section>
    <section id="methodik">
      <h2>Methodischer Ansatz</h2>
      <p>
        In einem ersten Schritt werden die bereinigten Redebeiträge mit Hilfe von
        <span class="glossary-term"
              data-definition="Topic Modelling ist ein Verfahren, mit dem aus großen Textsammlungen automatisch Themen (Topics) identifiziert werden, indem typische Wortmuster und Kookurrenzen analysiert werden.">
          Topic Modelling
        </span>
        untersucht. Dafür nutze ich das Framework <strong>BERTopic</strong>, das auf Transformer-basierten
        Sprachmodellen und einer anschließenden Clustering-Pipeline aufbaut.
      </p>
      <p>
        BERTopic nutzt u.&nbsp;a.
        <span class="glossary-term"
              data-definition="Embeddings sind numerische Vektorrepräsentationen von Wörtern oder Texten. Ähnliche Texte liegen in diesem Vektorraum näher beieinander als unähnliche.">
          Text-Embeddings
        </span>,
        um die Redebeiträge als Punkte in einem hochdimensionalen Raum zu repräsentieren. Anschließend
        wird mit
        <span class="glossary-term"
              data-definition="UMAP (Uniform Manifold Approximation and Projection) ist ein Verfahren zur Dimensionsreduktion, das hochdimensionale Daten in eine niedrigdimensionale Darstellung (z.B. 2D) überführt, wobei die Struktur der Daten möglichst gut erhalten bleibt.">
          UMAP
        </span>
        eine Dimensionsreduktion durchgeführt, bevor ein Dichte-basiertes
        Clustering-Verfahren wie
        <span class="glossary-term"
              data-definition="HDBSCAN ist ein hierarchisches, dichtebasiertes Clustering-Verfahren, das Cluster unterschiedlicher Dichte identifizieren kann und robust gegenüber Rauschen ist.">
          HDBSCAN
        </span>
        thematische Cluster identifiziert.
      </p>
      <p>
        Diese Pipeline erlaubt es, Themenbereiche und wiederkehrende Argumentationsmuster im Diskurs
        zu §218 sichtbar zu machen. Ergänzend plane ich eine (vorsichtige) Tonalitätsanalyse:
        Hier interessiert insbesondere, ob Beiträge eher konfrontativ oder konsensorientiert,
        moralisch aufgeladen oder pragmatisch-verwaltungsbezogen formuliert sind.
      </p>
      <p>
        <em>Offene Frage:</em> Welche Skala (z.&nbsp;B. „konfrontativ ↔ konsensorientiert“) ist für die
        Annotation von Tonalität sinnvoll und ausreichend trennscharf?
      </p>
    </section>
    <section id="fokus">
      <h2>Vertiefender Fokus: Datenaufbereitung – Herausforderungen und Lösungsansätze</h2>
      <h3>1. Relevante Debatten und Passagen identifizieren</h3>
      <p>
        §218 wird nicht immer exakt gleich zitiert. Neben expliziten Paragraphenverweisen
        („§218“, „§219a“) tauchen Begriffe wie „Schwangerschaftsabbruch“ oder „reproduktive
        Selbstbestimmung“ auf. Gleichzeitig gibt es rein formale oder technische Erwähnungen,
        die für die konkrete Forschungsfrage weniger relevant sind.
      </p>
      <p>
        Ich kombiniere deshalb eine Schlagwortsuche mit Kontextfiltern (z.&nbsp;B. Mindestlänge eines
        Redeabschnitts, mehrfaches Auftreten relevanter Begriffe) und nutze die TEI-Struktur, um
        gezielt Redebeiträge von Abgeordneten zu extrahieren. Stichprobenkontrollen helfen dabei,
        Suchmuster zu schärfen und sowohl Über- als auch Unterinklusion zu reduzieren.
      </p>
      <h3>2. Strukturierung der Redebeiträge und Metadaten</h3>
      <p>
        Für die spätere Analyse müssen die Daten in eine verlässliche Tabellenform gebracht werden.
        Dazu parse ich die XML/TEI-Dateien mit Python, extrahiere einzelne Redebeiträge und verknüpfe
        sie mit Metadaten wie Datum, Partei und – wenn verfügbar – Geschlecht der Redner*innen.
      </p>
      <p>
        Uneinheitliche Metadaten (z.&nbsp;B. unterschiedliche Schreibweisen von Parteinamen) werden
        normalisiert. Wo Informationen fehlen, dokumentiere ich diese Lücken transparent, statt
        sie stillschweigend zu füllen.
      </p>
      <h3>3. Textvorverarbeitung für Topic Modelling und Tonanalyse</h3>
      <p>
        Die Vorverarbeitung wird bewusst zurückhaltend gestaltet. Formelhafte Anreden und klar
        redundante Elemente können entfernt werden, um die Modelle nicht zu „verrauschen“. Gleichzeitig
        soll die stilistische und inhaltliche Vielfalt des Diskurses erhalten bleiben.
      </p>
      <p>
        Für Embedding-basierte Methoden wie BERTopic reicht meist eine leichte Normalisierung
        (z.&nbsp;B. Kleinschreibung, Bereinigung von Sonderzeichen). Stopword-Listen erweitere ich nur,
        wenn klar ist, dass bestimmte Wörter keinen Beitrag zur inhaltlichen Unterscheidung leisten.
      </p>
      <h3>4. Zwischenrufe und Plenumsreaktionen</h3>
      <p>
        Zwischenrufe, Heiterkeit oder Beifall werden in den Protokollen gesondert markiert und sind
        aus inhaltlicher Sicht ambivalent: Einerseits können sie auf Konfliktintensität oder
        Polarisierung hinweisen, andererseits erschweren sie die automatische Auswertung.
      </p>
      <p>
        Ich trenne diese Elemente technisch von den Hauptreden, lösche sie aber nicht vollständig.
        Stattdessen werden sie als zusätzliche Marker gespeichert, sodass ich Analysen mit und ohne
        diese Informationen vergleichen kann.
      </p>
      <h3>5. LLMs als Hilfswerkzeug in der Datenaufbereitung</h3>
      <p>
        LLMs können in der Datenaufbereitung unterstützen, etwa beim Vorschlagen von formelhaften
        Phrasen oder beim groben Vorsortieren von Abschnitten in „inhaltlich relevant“ vs.
        „formal/administrativ“. Alle Vorschläge werden jedoch manuell geprüft und in einem
        Prompt-Engineering-Journal dokumentiert.
      </p>
      <h3>6. Transparenz und Reproduzierbarkeit</h3>
      <p>
        Alle Skripte und Aufbereitungsschritte werden mit Git versioniert. Das Repository folgt einer
        klaren Struktur (z.&nbsp;B. <code>raw/</code>, <code>processed/</code>, <code>notebooks/</code>, <code>docs/</code>), und in
        zusätzlichen Markdown-Dokumenten (z.&nbsp;B. <code>DATA.md</code>, <code>METHOD.md</code>, <code>GLOSSAR.md</code>)
        werden Entscheidungen und offene Fragen nachvollziehbar festgehalten.
      </p>
    </section>
    <section id="projektplan">
      <h2>Mini-Projektplan</h2>
      <h3>Meilensteine</h3>
      <ol>
        <li>Datenakquise und Auswahl relevanter Plenarprotokolle zu §218</li>
        <li>Parsing der XML/TEI-Dateien und Aufbau eines analysierbaren Korpus</li>
        <li>Erste BERTopic-Modelle und Visualisierungen der Themenstruktur</li>
        <li>Vertiefende Analysen zur Tonalität und partei-/geschlechtsspezifischen Mustern</li>
        <li>Aufbereitung der Ergebnisse für Blog, Präsentation und spätere digitale Edition</li>
      </ol>
      <h3>Technologie-Stack</h3>
      <ul>
        <li>Python (Datenaufbereitung, Analyse)</li>
        <li>BERTopic, UMAP, HDBSCAN, Embedding-Modelle (NLP & Topic Modelling)</li>
        <li>Git &amp; GitHub (Versionierung), GitHub Pages (Publikation des Blogs)</li>
        <li>VSCode &amp; Jupyter-Notebooks als Arbeitsumgebung</li>
      </ul>
      <h3>Erwartete Herausforderungen</h3>
      <ul>
        <li>Saubere Trennung relevanter von irrelevanten Passagen in den Protokollen</li>
        <li>Interpretation von Tonalität in komplexen politischen Reden</li>
        <li>Reflektierter Einsatz von LLMs ohne unkritische Übernahme ihrer Vorschläge</li>
      </ul>
    </section>
    <section id="dokumentation">
      <h2>Dokumentation & nächste Schritte</h2>
      <p>
        Für Assignment 2 werden ergänzende Markdown-Dokumente vorbereitet, die parallel zum Blog
        gepflegt werden:
      </p>
      <ul>
        <li><code>GLOSSAR.md</code> – zentraler Begriffskatalog (erweitert im Vergleich zu den Tooltipps hier)</li>
        <li><code>DATA.md</code> – detaillierte Beschreibung des Datensatzes und der Aufbereitungsschritte</li>
        <li><code>METHOD.md</code> – technische Details zu BERTopic, UMAP, HDBSCAN und LLM-Einsatz</li>
      </ul>
      <p>
        Diese Dokumente entstehen ebenfalls in Zusammenarbeit mit einem LLM, werden aber von mir
        kontrolliert, kommentiert und bei Unsicherheit in Form offener Fragen formuliert.
      </p>
    </section>
    <section id="quellen">
      <h2>Quellen &amp; weiterführende Links</h2>
      <ul>
        <li>
          Deutscher Bundestag, Open Data: Plenarprotokolle und Drucksachen –
          <a href="https://www.bundestag.de/services/opendata" target="_blank" rel="noopener">
            https://www.bundestag.de/services/opendata
          </a>
        </li>
        <li>
          Übersicht Plenarprotokolle –
          <a href="https://www.bundestag.de/dokumente/protokolle/plenarprotokolle"
             target="_blank" rel="noopener">
            https://www.bundestag.de/dokumente/protokolle/plenarprotokolle
          </a>
        </li>
        <li>
          BERTopic – Dokumentation und Projektseite –
          <a href="https://bertopic.com/" target="_blank" rel="noopener">
            https://bertopic.com/
          </a>
        </li>
        <li>
          UMAP – Dimension Reduction –
          <a href="https://umap-learn.readthedocs.io/" target="_blank" rel="noopener">
            https://umap-learn.readthedocs.io/
          </a>
        </li>
        <li>
          HDBSCAN – Clustering-Bibliothek –
          <a href="https://hdbscan.readthedocs.io/" target="_blank" rel="noopener">
            https://hdbscan.readthedocs.io/
          </a>
        </li>
      </ul>
    </section>
  </main>
  <footer class="site-footer">
    <div class="container">
      <p>Forschungsblog im Rahmen eines Uni-Projekts · ParlaTONE</p>
      <p><a href="https://github.com/DEIN-USERNAME/DEIN-REPO" target="_blank" rel="noopener">
        GitHub-Repository</a></p>
    </div>
  </footer>
</body>
</html>
